# -*- coding: utf-8 -*-
"""Untitled8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GtAYNOP6itJIfr8HMNGfNWxV0kaqb34F
"""

import numpy as np
import random
import matplotlib.pyplot as plt


#  To generate our dataset:

X = np.arange(1, 50)
labels = np.arange(6, 55)
labels = [i + random.uniform(-4, 5) for i in labels]
plt.scatter(X, labels)



def find_cost(w, b, x, y, m):
    """
    Finding our Cost function (Mean Squared Error)
    """
    return (w*x + b - y)**2/(2*m)

def update_params(w, b, x, y, alpha, m):
    """
    Updating the values of W and B using partial differentiation
    """
    del_w = (1/(m))*(w*x + b - y)*x
    del_b = (1/(m))*(w*x + b - y)
    w = w - alpha * del_w
    b = b - alpha * del_b

    return w, b


cost = 0
m = len(X)
w_init, b_init = 0, 0
alpha = 0.01
for i in range(0, 20):  # traversing through the entire dataset 20 times
    
    cost = 0
    for x, y in zip(X, labels):  # for every "data point" in our dataset
        cost = cost + find_cost(w_init, b_init, x, y, m) # calculating the cost acrss all datapoints
        w, b = update_params(w_init, b_init, x, y, alpha, m) # updating w, b
        w_init, b_init = w, b
    print(cost)

y_pred = []
for x in X:
    y_pred.append(w*x + b) # finding our predicted values

plt.scatter(X, labels)      #plotting our graphs
plt.plot(X, y_pred)



# the same thing as above, but using library: scikit-learn (or sklearn)
from sklearn.linear_model import LinearRegression


reg = LinearRegression()

X = X.reshape(-1,1)
reg.fit(X, labels)

y_nicer = reg.predict(X)

"""
y_pred = []
for x in X:
    y_pred.append(w*x + b)
"""

y_nicer

labels



plt.scatter(X, labels)
plt.plot(X, y_nicer, 'g')

plt.scatter(X, labels)
plt.plot(X, y_pred)

